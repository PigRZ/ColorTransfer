## 由图像色彩迁移拓展到视频色彩迁移

---

### 存在的问题

所收集的四种图像色彩迁移方法中，作者提供的方法都是将源图像和参考图像进行整体的运算，这样影响算法速度的因素主要有两个，一个是源图像的分辨率，另一个是参考图像的分辨率。

拓展到视频色彩迁移中，多张源图像与参考图像进行色彩迁移，最简单直接的方法如下：

```
video:源视频，ref：参考图像，w：写入的视频
for frame in video:
	output=ColorTransfer(frame,ref)
	WriteVideo(w,output)
end for
```

这样的方法可行但是处理时间过长，由于帧间的大量相似性，每一次的色彩迁移都进行了大量的重复计算，这样的处理时间显然过长，以下是一次处理结果，使用的色彩迁移方法是Pipte的MKL方法，源视频的帧数有2559帧，分辨率为720\*1280，参考图像的分辨率为：5092\*3359（这里选用这么大的分辨率的图像作为参考图像是一种极端情况，每一轮次这么大的参考图像都参与运算是非常耗费时间的），由暴力算法得出的结果为2485秒≈41.4分钟。

---

### 改进思路

#### 总体思路

选择合适的色彩迁移方法兼顾色彩迁移效果和运算时间，扣除参考图的重复计算，减少帧间的重复计算。

由于减少了帧间的重复计算，并扣除了参考图的重复计算，那么**影响迁移结果的主要因素就是视频的分辨率和场景切换次数**。

#### 选择合适的色彩迁移方法

在前三周的结果中，实现了四种色彩迁移方法，分别是reinhard、Xiao、MKL和IDT方法，其中效果方面我的主观评价是IDT>MKL≈Xiao>reinhard，运行时间是IDT>MKL≈Xiao≈reinhard。因此兼顾运行时间和迁移效果，选择MKL方法作为改动。

查看MKL的源码（matlab）：

```
function IR = MKL(I0, I1)
%I0源图像，uint8
%I1源图像，uint8
%IR源图像，double
I0=im2double(I0);
I1=im2double(I1);
if (ndims(I0)~=3)
    error('pictures must have 3 dimensions');
end

X0 = reshape(I0, [], size(I0,3));
X1 = reshape(I1, [], size(I1,3));

A = cov(X0);
B = cov(X1);

T = MKL(A, B);

mX0 = repmat(mean(X0), [size(X0,1) 1]);
mX1 = repmat(mean(X1), [size(X0,1) 1]);

XR = (X0-mX0)*T + mX1;

IR = reshape(XR, size(I0));

function [T] = MKL(A, B)
N = size(A,1);
[Ua,Da2] = eig(A); 
Da2 = diag(Da2); 
Da2(Da2<0) = 0;
Da = diag(sqrt(Da2 + eps));
C = Da*Ua'*B*Ua*Da;
[Uc,Dc2] = eig(C); 
Dc2 = diag(Dc2);
Dc2(Dc2<0) = 0;
Dc = diag(sqrt(Dc2 + eps));
Da_inv = diag(1./(diag(Da)));
T = Ua*Da_inv*Uc*Dc*Uc'*Da_inv*Ua';
```

#### 去除参考图的重复计算

原始方法中每调用一次MKL色彩迁移方法，都是传入当前帧和参考图像，但是MKL方法中对于参考图像的运算是相同的，计算其方差、构造其均值矩阵，这在原始方法中的每一次调用都是同样的结果，所以将此部分提前到循环处理每帧之前，即可去除参考图像的重复计算，提高运算速度。

#### 减少帧间重复计算

经过我的测试，MKL源码中的变量T的运算的计算过程和当前帧的均值矩阵的构造过程耗时较长，MKL方法中的结果图像生成公式：

```
XR = (X0-mX0)*T + mX1;
```

其中X0是当前帧，mX0是X0的均值矩阵，mX1是参考图像的均值矩阵，T是由当前帧和参考图像的方差计算而来，观察这个公式，X0作为当前帧是不可复用的，mX1是固定值，尝试将mX0和T使用连续的前一帧的计算结果代入发现迁移结果几乎相同。那么**可以通过复用前一次计算生成的举止矩阵和变量T来减少重复计算，提高速度**。

那么需要思考一个问题如何评判前后两帧的是类似的呢，在何种情况下可以使用前一帧的计算结果。

受到最初老师发的那篇文章（EXAMPLE-BASED VIDEO COLOR TRANSFER）的启发，采用ssim（ 结构相似性 ）作为前后两帧是否相似的评判标准，当ssim大于0.7的时候就认为两帧类似，测试的视频转换结果与逐帧计算的效果几乎一致，但是测试结果显示并不能减少运算时间，这让我明白ssim的运算耗时比减少的帧间重复计算还要多。

那么需要其他的运算更简单的标准来评判前后帧的相似性，我对一个2500帧左右的视频中的每一帧，输出了该帧的方差、均值和与前一帧的相似度（ssim），发现到，当ssim小于0.7即可认为两帧不相似时，该帧的均值和方差也发生了一定程度的浮动，后续测试了几个视频也时差不多这样的情况，那么我就使用与前一帧的方差和均值差值同时作为场景切换评判标准。

**并且为了防止场景连续的帧数太多导致后续的帧迁移效果较差，规定了每一百连续帧要重新计算一次T和均值矩阵。**

---

### 测试结果

测试了4K、1080p、480p和360p各5个视频，都去除了参考图像的影响因素（若按原始方法，重复计算太多次参考图像会导致改进前后差距过大），改进前和改进后的测试结果如下：

| 分辨率 | 帧数 | 场景切换次数 | 改进前运行时间 | 改进后运行时间 | 改进幅度 |
| ------ | ---- | ------------ | -------------- | -------------- | -------- |
| 360p   | 2205 | 0            | 29.033         | 27.519         | 5.215%   |
| 480p   | 2205 | 0            | 48.151         | 45.451         | 5.607%   |
| 1080p  | 2205 | 0            | 271.571        | 208.311        | 23.294%  |
| 4k     | 2205 | 0            | 1081.341       | 852.082        | 21.201%  |
| 360p   | 2171 | 1            | 29.651         | 26.449         | 10.799%  |
| 480p   | 2171 | 1            | 53.895         | 44.689         | 17.081%  |
| 1080p  | 2171 | 1            | 255.043        | 221.182        | 13.277%  |
| 4k     | 2171 | 1            | 1039.233       | 840.8          | 19.094%  |
| 360p   | 1756 | 204          | 22.59          | 20.658         | 8.552%   |
| 480p   | 1756 | 207          | 41.309         | 37.081         | 10.235%  |
| 1080p  | 1756 | 215          | 192.783        | 174.3          | 9.587%   |
| 4k     | 1756 | 134          | 1569.774       | 1462.867       | 6.810%   |
| 360p   | 1854 | 1            | 25.341         | 19.869         | 21.593%  |
| 480p   | 1854 | 1            | 39.467         | 33.34          | 15.524%  |
| 1080p  | 1854 | 1            | 209.863        | 177.898        | 15.231%  |
| 4k     | 1854 | 1            | 1305.442       | 1163.132       | 10.901%  |
| 360p   | 360  | 3            | 4.85           | 4.159          | 14.247%  |
| 480p   | 360  | 3            | 8.564          | 7.011          | 18.134%  |
| 1080p  | 360  | 3            | 41.613         | 36.338         | 12.676%  |
| 4k     | 360  | 3            | 153.425        | 131.678        | 14.174%  |

可以看到改进幅度基本在5%-30%，并且对于不同视频具体的改进幅度是不一样的，而且同一个视频的不同分辨率在算法中判定的场景切换次数的不同的。另外的可以看到第三组视频的场景切换次数明显要比其他视频来的多，而其改进的幅度比其他组来的小，说明了视频场景切换次数越多，算法的改进效果就越不明显，视频越连续，改进效果越好，并且改进前后的色彩迁移效果基本一致。

---

### 总结

所做的工作是选取MKL方法作为图像色彩迁移方法，通过去除参考图像的重复计算，复用连续帧的前一帧的计算过程变量，减少重复计算，加快算法速度。

这种改进方法基于前后帧的变化，类似于视频压缩中的I帧和P帧，I帧完整保留，P帧保留与前帧的差别，当一个视频全是I帧时，这种改进方法就退化为原始方法甚至更慢，因为还要额外计算前后帧的差别，但是同样的，这也是个伪命题，每一帧都与前一帧不一样的视频应该不能称为视频而是一堆图像，而比如一个视频平均500帧有个I帧，那么这种改进方法就可以在不影响迁移效果的情况下有效减少运算时间。

